{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c34a37",
   "metadata": {},
   "source": [
    "This notebook loads the Wikidata-mc-trivia-71 dataset and evaluates our methods of surprise ranking on it\n",
    "\n",
    "## requirements\n",
    "* tqdm (`pip install tqdm`)\n",
    "* gensim (`pip install gensim`)\n",
    "* kgtk (follow documentation here: https://kgtk.readthedocs.io/en/latest/install/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "ef2ab2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import h5py, torch\n",
    "from torchbiggraph.model import ComplexDiagonalDynamicOperator, TranslationDynamicOperator, \\\n",
    "                                DotComparator, CosComparator, L2Comparator\n",
    "import json\n",
    "from utility import kgtk_to_dataframe\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from adjustText import adjust_text\n",
    "import glob\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "from functools import reduce, lru_cache\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "id": "2d5baf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the benchmark data\n",
    "surprise_data_file = \"./benchmark_data/mc_trivia_surprise_data.with_numeric_profile_qnodes.json\"\n",
    "\n",
    "# output path\n",
    "work_dir = \"./output/quiz_task\"\n",
    "# path where kypher db file will be saved\n",
    "store_dir = f\"{work_dir}/temp\"\n",
    "# Wikidata claims.wikibase-item file. We only need claims about humans for this dataset, so using a filtered file.\n",
    "item_file = \"./input_data/wikidata-20210215-dwd.claims.wikibase-item.q5.tsv.gz\"\n",
    "# Wikidata labels.en file.\n",
    "label_file = \"./input_data/labels.en.tsv.gz\"\n",
    "# paths to profile_labels_info_joined.RELs_and_AILs.tsv and entity_profile_labels.RELs_and_AILs.shuffled.tsv\n",
    "profile_labels_file = \"/data02/profiling/kgtk/entity_profiling/output/wikidata-20210215-dwd/explainability/profile_labels_info_joined.RELs_and_AILs.tsv\"\n",
    "ent_to_profiles_file = \"/data02/profiling/kgtk/entity_profiling/output/wikidata-20210215-dwd/explainability/entity_profile_labels.RELs_and_AILs.shuffled.tsv\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Paths to embedding folders...\n",
    "\n",
    "TODO for reproducing results:\n",
    "We don't store the embeddings on github because they are large.\n",
    "To include them in evaluation when running this notebook, you need to download them\n",
    "from google drive (location specified on github), and specify their locations below.\n",
    "\"\"\"\n",
    "emb_locations = {\n",
    "    # path to wikidata-20211027-dwd-v3.transe-embeddings folder\n",
    "    \"transe\": \"/data02/profiling/wikidata-20211027-dwd-v3.transe-embeddings\",\n",
    "    # path to wikidata-20210215-dwd.profile-transe-embeddings folder\n",
    "    \"profile-transe\": \"/data02/profiling/kgtk/entity_profiling/output/wikidata-20210215-dwd/profile_graph_embeddings/output\",\n",
    "    # path to wikidata-20210215-dwd-v2.complex-embeddings folder\n",
    "    \"complex\": \"/data02/profiling/wikidata-20210215-dwd-v2.complex-embeddings\",\n",
    "    # path to wikidata-20210215-dwd.profile-transe-embeddings folder\n",
    "    \"profile-complex\": \"/data02/profiling/kgtk/entity_profiling/output/wikidata-20210215-dwd/profile_graph_embeddings/complex_04292022/output\",\n",
    "    # path to \"Random walk embeddings\" folder\n",
    "    \"random_walk\": \"/data02/profiling/Random\\ walk\\ embeddings\",\n",
    "    # path to text_emb_subsets folder\n",
    "    \"text_emb_subsets\": \"/data02/profiling/dwd-v3.class_subsets\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0cfb7a",
   "metadata": {},
   "source": [
    "### Process params / set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bcf0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure paths are absolute\n",
    "work_dir = os.path.abspath(work_dir)\n",
    "store_dir = os.path.abspath(store_dir)\n",
    "label_file = os.path.abspath(label_file)\n",
    "    \n",
    "# Create directories\n",
    "if not os.path.exists(store_dir):\n",
    "    os.makedirs(store_dir)\n",
    "    \n",
    "# adding some environment variables we'll be using frequently\n",
    "os.environ['STORE'] = \"{}/wikidata.sqlite3.db\".format(store_dir)\n",
    "os.environ['LABELS'] = label_file\n",
    "\n",
    "# set up embedding file locations\n",
    "# info for embedding models that we want to use for link prediction.\n",
    "lp_embedding_models_info = {\n",
    "    \"transe\": {\"base_dir\": emb_locations[\"transe\"],\n",
    "               \"model_v_num\": \"v600\",\n",
    "               \"operator\": \"translation\",\n",
    "               \"dim\": 100\n",
    "              },\n",
    "    \"profile-transe\": {\"base_dir\": emb_locations[\"profile-transe\"],\n",
    "               \"model_v_num\": \"v100\",\n",
    "               \"operator\": \"translation\",\n",
    "               \"dim\": 100\n",
    "              },\n",
    "    \"complex\": {\"base_dir\": emb_locations[\"complex\"],\n",
    "               \"model_v_num\": \"v600\",\n",
    "               \"operator\": \"complex_diagonal\",\n",
    "               \"dim\": 100\n",
    "              },\n",
    "    \"profile-complex\": {\"base_dir\": emb_locations[\"profile-complex\"],\n",
    "               \"model_v_num\": \"v100\",\n",
    "               \"operator\": \"complex_diagonal\",\n",
    "               \"dim\": 100\n",
    "              },\n",
    "}\n",
    "\n",
    "kv_embedding_files = {\"H\" : f\"{emb_locations[random_walk]}/h_embeddings_5x8,min_count=21.kv\",\n",
    "                   \"A\" : f\"{emb_locations[random_walk]}/a_embeddings_10x10,min_count=0.kv\",\n",
    "                   \"S\" : f\"{emb_locations[random_walk]}/s_embeddings_5x10,min_count=0.kv\",\n",
    "                  }\n",
    "\n",
    "# kv_embedding_files = {\"H\" : \"/data02/profiling/kgtk/entity_profiling/output/wikidata-20210215-dwd/H_walks_analysis/h_embeddings_5x8,min_count=21.kv\",\n",
    "#                    \"A\" : \"/data02/profiling/kgtk/entity_profiling/output/wikidata-20210215-dwd/A_walks_analysis/a_embeddings_10x10,min_count=0.kv\",\n",
    "#                    \"S\" : \"/data02/profiling/kgtk/entity_profiling/output/wikidata-20210215-dwd/S_walks_analysis/s_embeddings_5x10,min_count=0.kv\",\n",
    "#                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c1b5e",
   "metadata": {},
   "source": [
    "### Load various things: profile labels, english labels, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604e81b2",
   "metadata": {},
   "source": [
    "Load profile labels (reusing profiles created by \"Generating Explainable Abstractions for Wikidata Entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d3a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_labels_df = pd.read_csv(profile_labels_file, sep='\\t', dtype=str).fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73255a",
   "metadata": {},
   "source": [
    "add english labels to profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceeaac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_en_df = pd.read_csv(label_file, sep='\\t')\n",
    "labels_en_dict = dict(zip(labels_en_df.node1, labels_en_df.node2))\n",
    "def remove_lang_tag(label):\n",
    "    return label[1:-4]\n",
    "# Note this code assumes we are only using AILs and RELs\n",
    "plab_labels = []\n",
    "for _, row in tqdm(profile_labels_df.iterrows(), total=len(profile_labels_df)):\n",
    "    type_label = remove_lang_tag(row[\"type_label\"])\n",
    "    property_label = remove_lang_tag(row[\"property_label\"])\n",
    "    if row[\"node2\"] != \"\":\n",
    "        if row[\"node2\"] in labels_en_dict:\n",
    "            value_label = remove_lang_tag(labels_en_dict[row[\"node2\"]])\n",
    "        else:\n",
    "            value_label = row[\"node2\"]\n",
    "    else:\n",
    "        lb = row[\"lower_bound\"]\n",
    "        ub = row[\"upper_bound\"]\n",
    "        value_label = f\"{lb}-{ub}\"\n",
    "        si = row[\"si_units\"]\n",
    "        wd = row[\"wd_units\"]\n",
    "        if wd != \"\":\n",
    "            if wd in labels_en_dict:\n",
    "                wd = remove_lang_tag(labels_en_dict[wd])\n",
    "            value_label = value_label + f\" {wd}\"\n",
    "        elif si != \"\":\n",
    "            value_label = value_label + f\" {si}\"\n",
    "    plab_labels.append(f\"{type_label}, {property_label}, {value_label}\")\n",
    "profile_labels_df[\"plab_label\"] = plab_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e18d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim profile_labels_df to just columns we need\n",
    "profile_labels_df = profile_labels_df.loc[:,[\"id\", \"plab_label\", \"support\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb65a21",
   "metadata": {},
   "source": [
    "set up dictionaries for profile-label to entities and vice-versa to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a12f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 2s, sys: 23.6 s, total: 2min 25s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "entity_prof_labels_df = pd.read_csv(ent_to_profiles_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec13fa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 39s, sys: 39.7 s, total: 11min 19s\n",
      "Wall time: 11min 18s\n"
     ]
    }
   ],
   "source": [
    "%time ent_to_labels_dict = entity_prof_labels_df.groupby('node1')['node2'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52972693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 7.19 s, total: 1min 32s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%time label_to_ents_dict = entity_prof_labels_df.groupby('node2')['node1'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c986f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del entity_prof_labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e13c00",
   "metadata": {},
   "source": [
    "#### Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "896c414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da50dac",
   "metadata": {},
   "source": [
    "embeddings that we have link prediction files for (complex, transe, profile-complex, profile-transe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "id": "045546b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55471746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile-transe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26894849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53002670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lp_emb_name, model_info_dict in lp_embedding_models_info.items():\n",
    "    print(lp_emb_name)\n",
    "    base_dir = model_info_dict[\"base_dir\"]\n",
    "    model_v_num = model_info_dict[\"model_v_num\"]\n",
    "    entity_names_list = json.load(open(f\"{base_dir}/entity_names_all_0.json\"))\n",
    "\n",
    "    # Load the embeddings\n",
    "    with h5py.File(f\"{base_dir}/model/embeddings_all_0.{model_v_num}.h5\", \"r\") as hf:\n",
    "        embeddings = hf[\"embeddings\"][...]\n",
    "\n",
    "    embedding_models[lp_emb_name] = {}\n",
    "    for i in tqdm(range(len(entity_names_list))):\n",
    "        embedding_models[lp_emb_name][entity_names_list[i]] = embeddings[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "id": "a0e13f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile-complex\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93528fce952a47f686e74ba3c65bf2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26894849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lp_emb_name, model_info_dict in lp_embedding_models_info.items():\n",
    "    if lp_emb_name in embedding_models:\n",
    "        continue\n",
    "    print(lp_emb_name)\n",
    "    base_dir = model_info_dict[\"base_dir\"]\n",
    "    model_v_num = model_info_dict[\"model_v_num\"]\n",
    "    entity_names_list = json.load(open(f\"{base_dir}/entity_names_all_0.json\"))\n",
    "\n",
    "    # Load the embeddings\n",
    "    with h5py.File(f\"{base_dir}/model/embeddings_all_0.{model_v_num}.h5\", \"r\") as hf:\n",
    "        embeddings = hf[\"embeddings\"][...]\n",
    "\n",
    "    embedding_models[lp_emb_name] = {}\n",
    "    for i in tqdm(range(len(entity_names_list))):\n",
    "        embedding_models[lp_emb_name][entity_names_list[i]] = embeddings[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869a0b62",
   "metadata": {},
   "source": [
    "PCA text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d1b13e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f7d7037de445199cef1a5587917fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_text_emb_file = \"/data02/profiling/dwd-v3.text-embeddings.PCA100/faiss_index/kgtk_text_embeddings_all.PCA100.tsv\"\n",
    "text_emb_df = pd.read_csv(pca_text_emb_file, sep='\\t')\n",
    "text_emb_dict = {}\n",
    "for _, row in tqdm(text_emb_df.iterrows()):\n",
    "    ent = row[\"node1\"]\n",
    "    embed = np.float32(row[\"node2\"].split(','))\n",
    "    text_emb_dict[ent] = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4ea64b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_models[\"pca100_text\"] = text_emb_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d91710b",
   "metadata": {},
   "source": [
    "Original text embeddings (subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8eb71280",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_embed_subsets_dir = \"/data02/profiling/dwd-v3.class_subsets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "788a5c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file /data02/profiling/dwd-v3.class_subsets/Q5.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32beaaf9524a47fd96e59af2ef84821b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file /data02/profiling/dwd-v3.class_subsets/Q3624078.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83458144c7804a3eac4bfdd1ba7330d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file /data02/profiling/dwd-v3.class_subsets/Q532.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0d2561b6954942b030a8ffd1b78e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file /data02/profiling/dwd-v3.class_subsets/Q23442.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4987a86e3fbf4fa29a7a08e921380527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file /data02/profiling/dwd-v3.class_subsets/Q783794.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f70d9c8ad04d60bf2c8bbaf30b7355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file /data02/profiling/dwd-v3.class_subsets/Q3305213.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a2f8ebe34e4197aad86943193e38ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file /data02/profiling/dwd-v3.class_subsets/Q11424.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4809ea7e8e3c401888b153896e851563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file /data02/profiling/dwd-v3.class_subsets/Q7725634.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a73229afeb34f54900f900c2c3d3e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file /data02/profiling/dwd-v3.class_subsets/Q571.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b901e5ddac44febb7cdddc5a256b31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file /data02/profiling/dwd-v3.class_subsets/Q47461344.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4bd93b3c2f4e6aa42f5871a051c67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from file /data02/profiling/dwd-v3.class_subsets/Q4830453.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dc022a542745d7aa117b4aacc0cf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig_embed_dict = {}\n",
    "for filename in glob.glob(f\"{orig_embed_subsets_dir}/*\"):\n",
    "    print(f\"loading from file {filename}\")\n",
    "    embedding_df = pd.read_csv(filename, sep='\\t')\n",
    "    for _, row in tqdm(embedding_df.iterrows()):\n",
    "        ent = row[\"node1\"]\n",
    "        embed = np.float32(row[\"node2\"].split(','))\n",
    "        orig_embed_dict[ent] = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fcbd1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_models[\"text1024\"] = orig_embed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725cf41b",
   "metadata": {},
   "source": [
    "random walk embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "id": "f10dd660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f679559ba545f89e5012c0e1830a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading H embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c01b3d2f7bc4b658b8197936664a24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19593942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading A embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe9e09a4db74f3da42a5276923c4a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12106870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading S embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3cfade3f1d437abaf20de7ae1b6720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39030788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 14s, sys: 1min 31s, total: 5min 46s\n",
      "Wall time: 6min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for name, file_path in tqdm(kv_embedding_files.items()):\n",
    "    print(\"now loading {} embeddings\".format(name))\n",
    "    emb_dict = {}\n",
    "    kv_model = KeyedVectors.load(file_path)\n",
    "    for key, index in tqdm(kv_model.key_to_index.items()):\n",
    "        emb_dict[key] = kv_model.vectors[index]\n",
    "    embedding_models[name] = emb_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182f441",
   "metadata": {},
   "source": [
    "## Methods for computing measure of surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "id": "a12b83a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_profile_labels_set(ent, ent_to_labels_dict=None):\n",
    "    if ent_to_labels_dict is not None and ent in ent_to_labels_dict:\n",
    "        return set(ent_to_labels_dict[ent])\n",
    "    res = !kgtk query -i {ent_to_profiles_file} --graph-cache $STORE \\\n",
    "          --match 'profile_labels: (ent)-[]->(profile_label_id)' \\\n",
    "          --return 'distinct profile_label_id' \\\n",
    "          --where 'ent = \"{ent}\"'\n",
    "    return set(kgtk_to_dataframe(res).loc[:,\"node2\"])\n",
    "    \n",
    "def get_entity_profile_labels_df(profile_labels_df, ent, ent_to_labels_dict=None):\n",
    "    labels = get_entity_profile_labels_set(ent, ent_to_labels_dict)\n",
    "    return profile_labels_df.loc[profile_labels_df.loc[:,\"id\"].isin(labels),:]\n",
    "\n",
    "def get_entities_with_profile_label(label_id, ent_to_omit=None, limit=1000, label_to_ents_dict=None):\n",
    "    if label_to_ents_dict is not None and label_id in label_to_ents_dict:\n",
    "        ents = list(label_to_ents_dict[label_id])\n",
    "        if ent_to_omit is not None and ent_to_omit in ents:\n",
    "            ents.remove(ent_to_omit)\n",
    "        return set(np.random.choice(ents, min(len(ents),limit), replace=False))\n",
    "    res = !kgtk query -i {ent_to_profiles_file} --graph-cache $STORE \\\n",
    "        --match 'profile_labels: (ent)-[]->(profile_label_id)' \\\n",
    "        --return 'distinct ent' \\\n",
    "        --where 'ent != \"{ent_to_omit}\" AND profile_label_id = \"{label_id}\"' \\\n",
    "        --limit {limit}\n",
    "    return set(kgtk_to_dataframe(res).loc[:,\"node1\"])\n",
    "\n",
    "def get_ents_of_type(ent_to_omit, ent_type, limit=1000):\n",
    "    res = !kgtk query -i {ent_to_profiles_file} --graph-cache $STORE \\\n",
    "        --match 'profile_labels: (ent)-[]->(profile_label_id)' \\\n",
    "        --return 'distinct ent' \\\n",
    "        --where 'ent != \"{ent_to_omit}\" AND printf(\"%.{len(ent_type)}s\", profile_label_id) = \"{ent_type}\"' \\\n",
    "        --limit {limit}\n",
    "    return set(kgtk_to_dataframe(res).loc[:,\"node1\"])\n",
    "\n",
    "def compute_surprise_metrics_for_sample(ent, sample_ents, embedding_dict, pairwise_disp_args,\n",
    "                                        pairwise_sample=10000):\n",
    "    ret = {}\n",
    "    \n",
    "    # get embeddings\n",
    "    sample_embeds = np.array([embedding_dict[s] for s in sample_ents if s in embedding_dict])\n",
    "    ent_embed = embedding_dict[ent]\n",
    "\n",
    "    # centroid-based measures\n",
    "    centroid = np.mean(sample_embeds, axis=0)\n",
    "    dists = np.array([distance.cosine(centroid, e) for e in sample_embeds])\n",
    "    avg_sample_to_centroid = np.mean(dists)\n",
    "    ret[\"dispersion (centroid)\"] = avg_sample_to_centroid\n",
    "    ent_to_centroid = distance.cosine(centroid, ent_embed)\n",
    "    ret[\"distance (centroid)\"] = ent_to_centroid\n",
    "    ret[\"distance(centroid)/dispersion(centroid)\"] = ent_to_centroid / avg_sample_to_centroid\n",
    "\n",
    "    # avg sample dist to entity of interest\n",
    "    ent_dists = np.array([distance.cosine(ent_embed, e) for e in sample_embeds])\n",
    "    avg_ent_to_sample = np.mean(ent_dists)\n",
    "    ret[\"distance (avg pairwise)\"] = avg_ent_to_sample\n",
    "    ret[\"distance(avg pairwise)/dispersion(centroid)\"] = avg_ent_to_sample / avg_sample_to_centroid\n",
    "\n",
    "    # avg pairwise dist within sample\n",
    "    avg_sample_to_sample = compute_avg_pairwise_dist_in_sample(pairwise_disp_args[\"fact_ids\"],\n",
    "                                                               pairwise_disp_args[\"class\"],\n",
    "                                                               pairwise_disp_args[\"emb_name\"],\n",
    "                                                               pairwise_sample\n",
    "                                                              )\n",
    "    ret[\"dispersion (avg pairwise)\"] = avg_sample_to_sample\n",
    "    ret[\"distance(avg pairwise)/dispersion(avg pairwise)\"] = avg_ent_to_sample / avg_sample_to_sample\n",
    "        \n",
    "    return ret\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def compute_avg_pairwise_dist_in_sample(fact_ids, ent_class, emb_name, pairwise_sample=10000):\n",
    "    \"\"\"\n",
    "    Assumptions:\n",
    "        * label_to_ents_dict exists and is accessible here\n",
    "        * embedding_models exists and is accessible here\n",
    "    \"\"\"\n",
    "    # first get sample\n",
    "    if fact_ids is not None:\n",
    "        assert ent_class is None, \"One of fact_ids or ent_class should be None.\"\n",
    "        fact_ids = fact_ids.split(\"|\")\n",
    "        sample_ents = set()\n",
    "        for fact in fact_ids:\n",
    "            sample_ents = sample_ents | get_entities_with_profile_label(fact, \"\", pairwise_sample, label_to_ents_dict)\n",
    "    elif ent_class is not None:\n",
    "        sample_ents = get_ents_of_type(\"\", ent_class, pairwise_sample)\n",
    "    else:\n",
    "        assert False, \"Both fact_ids and ent_class are None\"\n",
    "        \n",
    "    # choose embedding model we are using\n",
    "    embedding_dict = embedding_models[emb_name]\n",
    "    \n",
    "    # get embeddings\n",
    "    sample_embeds = np.array([embedding_dict[s] for s in sample_ents if s in embedding_dict])\n",
    "    # avg pairwise dist within sample\n",
    "    sample_dists = []\n",
    "    for i in range(pairwise_sample):\n",
    "        e1, e2 = sample_embeds[np.random.choice(sample_embeds.shape[0], size=2, replace=False), :]\n",
    "#         e1, e2 = random.sample(list(sample_embeds), 2) # Slower\n",
    "        sample_dists.append(distance.cosine(e1, e2))\n",
    "    avg_sample_to_sample = np.mean(sample_dists)\n",
    "    return avg_sample_to_sample\n",
    "\n",
    "def compute_avg_dist_from_ent_to_sample(ent, sample_ents, embedding_dict):\n",
    "    # get embeddings\n",
    "    ent_embed = embedding_dict[ent]\n",
    "    sample_embeds = np.array([embedding_dict[s] for s in sample_ents if s in embedding_dict])\n",
    "    # avg sample dist to entity of interest\n",
    "    ent_dists = np.array([distance.cosine(ent_embed, e) for e in sample_embeds])\n",
    "    avg_ent_to_sample = np.mean(ent_dists)\n",
    "    return avg_ent_to_sample\n",
    "\n",
    "def compute_surprise_metrics_for_ent_fact(ent, fact_ids, emb_name, embedding_dict, label_to_ents_dict=None,\n",
    "                                          sample=10000, pairwise_sample=10000):\n",
    "    # fact_ids are used to form the sample by taking union of samples for each fact\n",
    "    ents_sharing_label = set()\n",
    "    for fact in fact_ids:\n",
    "        ents_sharing_label = ents_sharing_label | get_entities_with_profile_label(fact, ent, sample, label_to_ents_dict)\n",
    "    \n",
    "    # Information needed to get a sample of embeddings\n",
    "    # When calculating pairwise dispersion of sample,\n",
    "    # we'll cache the result and use these values as keys.\n",
    "    pairwise_disp_args = {\"fact_ids\": \"|\".join(fact_ids),\n",
    "                          \"class\": None,\n",
    "                          \"emb_name\": emb_name\n",
    "                         }\n",
    "    metrics_dict = compute_surprise_metrics_for_sample(ent, ents_sharing_label, embedding_dict, pairwise_disp_args, pairwise_sample)\n",
    "        \n",
    "    return metrics_dict\n",
    "\n",
    "def compute_surprise_metrics_for_df(ent, facts_df, embedding_models, label_to_ents_dict=None, sample=10000, pairwise_sample=10000):\n",
    "    label_ids = facts_df.loc[:,\"id\"]\n",
    "    \n",
    "    # for each profile label, sample entities and compute surprise metrics with each embedding model\n",
    "    metrics_dict = {}\n",
    "    for label_id in tqdm(label_ids):\n",
    "        ents_sharing_label = get_entities_with_profile_label(label_id, ent, sample, label_to_ents_dict)\n",
    "        # Information needed to get a sample of embeddings\n",
    "        # When calculating pairwise dispersion of sample,\n",
    "        # we'll cache the result and use these values as keys.\n",
    "        pairwise_disp_args = {\"fact_ids\": label_id,\n",
    "                              \"class\": None,\n",
    "                             }\n",
    "        for name, embedding_dict in embedding_models.items():\n",
    "            pairwise_disp_args[\"emb_name\"] = name\n",
    "            label_metrics = compute_surprise_metrics_for_sample(ent, ents_sharing_label, embedding_dict, pairwise_disp_args, pairwise_sample)\n",
    "            for k, v in label_metrics.items():\n",
    "                emb_specific_key = f\"{k} - {name}\"\n",
    "                if emb_specific_key not in metrics_dict:\n",
    "                    metrics_dict[emb_specific_key] = []\n",
    "                metrics_dict[emb_specific_key].append(v)\n",
    "        \n",
    "    for k, v in metrics_dict.items():\n",
    "        facts_df.loc[:,k] = v\n",
    "    \n",
    "    return facts_df\n",
    "\n",
    "def compute_surprise_metrics_sampling_by_type(ent, ent_type, embedding_models,\n",
    "                                              sample=10000, pairwise_sample=10000):\n",
    "    ents_sharing_type = get_ents_of_type(ent, ent_type, sample)\n",
    "    # Information needed to get a sample of embeddings\n",
    "    # When calculating pairwise dispersion of sample,\n",
    "    # we'll cache the result and use these values as keys.\n",
    "    pairwise_disp_args = {\"fact_ids\": None,\n",
    "                          \"class\": ent_type,\n",
    "                         }\n",
    "    metrics_dict = {}\n",
    "    for name, embedding_dict in embedding_models.items():\n",
    "        pairwise_disp_args[\"emb_name\"] = name\n",
    "        class_metrics = compute_surprise_metrics_for_sample(ent, ents_sharing_type, embedding_dict,\n",
    "                                                            pairwise_disp_args, pairwise_sample)\n",
    "        metrics_dict[name] = class_metrics\n",
    "        \n",
    "    return metrics_dict\n",
    "\n",
    "# Baselines for measuring surprise\n",
    "def get_surprise_scores_random(fact_ids):\n",
    "    return np.random.rand(len(fact_ids))\n",
    "\n",
    "def get_surprise_scores_freq(fact_ids, profile_labels_df):\n",
    "    scores = []\n",
    "    for f_ids in fact_ids:\n",
    "        # handle multiple fact ids (see \"canvas\" answer in mc quiz)\n",
    "        freq = 0\n",
    "        for f_id in f_ids:\n",
    "            freq += float(profile_labels_df.loc[profile_labels_df[\"id\"].values == f_id, \"support\"])\n",
    "        scores.append(1-freq)\n",
    "    return scores\n",
    "\n",
    "# updating and displaying avg question correlation\n",
    "def update_corr_measures(questions):\n",
    "    for q in questions:\n",
    "        ans_surprise_gts = [ans[\"gt_surprise\"] for ans in q[\"answers\"]]\n",
    "        for method_name in q[\"answers\"][0][\"method_surprise_scores\"]:\n",
    "            ans_surprise_preds = [ans[\"method_surprise_scores\"][method_name] for ans in q[\"answers\"]]\n",
    "            rho, _ = spearmanr(ans_surprise_gts, ans_surprise_preds)\n",
    "            tau, _ = kendalltau(ans_surprise_gts, ans_surprise_preds)\n",
    "            q[\"method_spearman\"][method_name] = rho\n",
    "            q[\"method_kendalltau\"][method_name] = tau\n",
    "            \n",
    "def display_avg_question_corr(question_subsets, method_names):\n",
    "    header = [\"\"]\n",
    "    for name in question_subsets:\n",
    "        header.append(f\"Rho ({name})\")\n",
    "        header.append(f\"Tau ({name})\")\n",
    "    rows = []\n",
    "    for method_name in method_names:\n",
    "        row = [method_name]\n",
    "        for question_subset in question_subsets.values():\n",
    "            rhos = []\n",
    "            taus = []\n",
    "            for q in question_subset:\n",
    "                # check if not all questions in subset can be evaluated with this method\n",
    "                if method_name not in q[\"method_spearman\"]:\n",
    "                    break\n",
    "                rhos.append(q[\"method_spearman\"][method_name])\n",
    "                taus.append(q[\"method_kendalltau\"][method_name])\n",
    "            # if can't eval all questions in subset with this method, don't evaluate on it\n",
    "            if len(rhos) != len(question_subset):\n",
    "                row.extend([\"-\", \"-\"])\n",
    "            else:\n",
    "                r = np.mean(rhos)\n",
    "                t = np.mean(taus)\n",
    "                row.append(f\"{r:.3f}\")\n",
    "                row.append(f\"{t:.3f}\")\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=header)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8585ed75",
   "metadata": {},
   "source": [
    "## Load MC quiz data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "id": "dc4ccc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(surprise_data_file, 'r') as f:\n",
    "    questions = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022b5513",
   "metadata": {},
   "source": [
    "Add profile label ids for each answer and an empty dict for storing computed method surprise scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "a74f8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_profile_labels = set(profile_labels_df.loc[:,\"id\"])\n",
    "# reconstructing and validating profile labels for each question / answer\n",
    "for i, q in enumerate(questions):\n",
    "    for answer in q[\"answers\"]:\n",
    "        ans_fact_ids = []\n",
    "        for qnode in answer[\"qnodes\"]:\n",
    "            fact_id = \"{}_{}_{}\".format(q[\"class\"], q[\"property\"], qnode)\n",
    "            if q[\"wd_units\"] is not None:\n",
    "                fact_id += \"__\" + q[\"wd_units\"]\n",
    "            assert fact_id in all_profile_labels, f\"{fact_id} not found in loaded profile labels\\n\" +\\\n",
    "                f\"Question {i}: \\'{q['lexicalized']}\\'\"\n",
    "            ans_fact_ids.append(fact_id)\n",
    "        answer[\"fact_ids\"] = ans_fact_ids\n",
    "        # also initialize dict for storing computed surprise scores\n",
    "        answer[\"method_surprise_scores\"] = {}\n",
    "    q[\"method_spearman\"] = {}\n",
    "    q[\"method_kendalltau\"] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2508167",
   "metadata": {},
   "source": [
    "## Correlation of facts within single question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b476402",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "26481273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ae637add1b49afb9a95b0d098adbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Spearman</th>\n",
       "      <th>KT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frequency</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Spearman     KT\n",
       "0     random    0.003  0.003\n",
       "1  frequency    0.066  0.074"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_trials = 500\n",
    "\n",
    "for q in tqdm(questions):\n",
    "    \n",
    "    ans_surprise_gts = [ans[\"gt_surprise\"] for ans in q[\"answers\"]]\n",
    "    fact_ids = [ans[\"fact_ids\"] for ans in q[\"answers\"]]\n",
    "    \n",
    "    # random\n",
    "    q[\"method_spearman\"][\"random\"] = []\n",
    "    q[\"method_kendalltau\"][\"random\"] = []\n",
    "    for i in range(num_trials):\n",
    "        random_preds = get_surprise_scores_random(fact_ids)\n",
    "        r, r_pval = spearmanr(ans_surprise_gts, random_preds)\n",
    "        t, t_pval = kendalltau(ans_surprise_gts, random_preds)\n",
    "        q[\"method_spearman\"][\"random\"].append(r)\n",
    "        q[\"method_kendalltau\"][\"random\"].append(t)\n",
    "    q[\"method_spearman\"][\"random\"] = np.mean(q[\"method_spearman\"][\"random\"])\n",
    "    q[\"method_kendalltau\"][\"random\"] = np.mean(q[\"method_kendalltau\"][\"random\"])\n",
    "    \n",
    "    # freq\n",
    "    freq_preds = get_surprise_scores_freq(fact_ids, profile_labels_df)\n",
    "    # if freqs are all the same, fall back to random.\n",
    "    if all(freq_preds[0] == np.array(freq_preds)):\n",
    "        q[\"method_spearman\"][\"frequency\"] = q[\"method_spearman\"][\"random\"]\n",
    "        q[\"method_kendalltau\"][\"frequency\"] = q[\"method_kendalltau\"][\"random\"]\n",
    "    else:\n",
    "        r, r_pval = spearmanr(ans_surprise_gts, freq_preds)\n",
    "        t, t_pval = kendalltau(ans_surprise_gts, freq_preds)\n",
    "        q[\"method_spearman\"][\"frequency\"] = r\n",
    "        q[\"method_kendalltau\"][\"frequency\"] = t\n",
    "header = [\"\", \"Spearman\", \"KT\"]\n",
    "rows = []\n",
    "for method in [\"random\", \"frequency\"]:\n",
    "    r = np.mean([q[\"method_spearman\"][method] for q in questions])\n",
    "    t = np.mean([q[\"method_kendalltau\"][method] for q in questions])\n",
    "    rows.append([method,\n",
    "                 f\"{r:.3f}\",\n",
    "                 f\"{t:.3f}\",\n",
    "                ])\n",
    "df = pd.DataFrame(rows, columns=header)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84260f6",
   "metadata": {},
   "source": [
    "Now splitting by different question subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "id": "bb577e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnode_questions = [q for q in questions if not q[\"is_numeric_answer\"]]\n",
    "numeric_questions = [q for q in questions if q[\"is_numeric_answer\"]]\n",
    "single_ans_questions = [q for q in questions if q[\"is_single_answer\"]]\n",
    "multi_ans_questions = [q for q in questions if not q[\"is_single_answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "id": "e376a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_subsets = {\"qnode\": qnode_questions,\n",
    "                    \"num\": numeric_questions,\n",
    "                    \"all\": questions,\n",
    "                    \"single\": single_ans_questions,\n",
    "                    \"multi\": multi_ans_questions,\n",
    "                   }\n",
    "header = [\"\"]\n",
    "for name in question_subsets:\n",
    "    header.append(f\"Rho ({name})\")\n",
    "    header.append(f\"Tau ({name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "15ed4057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Rho (qnode)</th>\n",
       "      <th>Tau (qnode)</th>\n",
       "      <th>Rho (num)</th>\n",
       "      <th>Tau (num)</th>\n",
       "      <th>Rho (single)</th>\n",
       "      <th>Tau (single)</th>\n",
       "      <th>Rho (multi)</th>\n",
       "      <th>Tau (multi)</th>\n",
       "      <th>Rho (all)</th>\n",
       "      <th>Tau (all)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frequency</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rho (qnode) Tau (qnode) Rho (num) Tau (num) Rho (single)  \\\n",
       "0     random      -0.003      -0.002     0.024     0.019        0.023   \n",
       "1  frequency       0.043       0.055     0.134     0.129        0.108   \n",
       "\n",
       "  Tau (single) Rho (multi) Tau (multi) Rho (all) Tau (all)  \n",
       "0        0.019      -0.005      -0.003     0.003     0.003  \n",
       "1        0.095       0.049       0.065     0.066     0.074  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "for method in [\"random\", \"frequency\"]:\n",
    "    row = [method]\n",
    "    for question_subset in question_subsets.values():\n",
    "        r = np.mean([q[\"method_spearman\"][method] for q in question_subset])\n",
    "        t = np.mean([q[\"method_kendalltau\"][method] for q in question_subset])\n",
    "        row.append(f\"{r:.3f}\")\n",
    "        row.append(f\"{t:.3f}\")\n",
    "    rows.append(row)\n",
    "df = pd.DataFrame(rows, columns=header)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c14bc1",
   "metadata": {},
   "source": [
    "### Statistical methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "id": "628f3870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce149e537a644e04b5a611f984ef7e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "surprise_metric_abbrevs = {'distance(avg pairwise)/dispersion(avg pairwise)': \"ap/ap\",\n",
    "                           'distance(centroid)/dispersion(centroid)': \"c/c\",\n",
    "                           'distance(avg pairwise)/dispersion(centroid)': \"ap/c\"\n",
    "                          }\n",
    "\n",
    "for q, answer in tqdm([(q, answer) for q in questions for answer in q[\"answers\"]]):\n",
    "    ent = q[\"entity\"]\n",
    "    fact_ids = answer[\"fact_ids\"]\n",
    "    for emb_name, embedding_dict in embedding_models.items():\n",
    "        # following if block with avoid recomputing already-computed methods\n",
    "        if f\"{emb_name}, ap/ap\" in answer[\"method_surprise_scores\"]:\n",
    "            continue\n",
    "        metrics_dict = compute_surprise_metrics_for_ent_fact(ent, fact_ids, emb_name, embedding_dict, label_to_ents_dict)\n",
    "        for metric_name, abbrev in surprise_metric_abbrevs.items():\n",
    "            method_name = f\"{emb_name}, {abbrev}\"\n",
    "            answer[\"method_surprise_scores\"][method_name] = metrics_dict[metric_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330f95d",
   "metadata": {},
   "source": [
    "Compute per-question correlation and view avg correlation in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "id": "1bf325c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Rho (qnode)</th>\n",
       "      <th>Tau (qnode)</th>\n",
       "      <th>Rho (num)</th>\n",
       "      <th>Tau (num)</th>\n",
       "      <th>Rho (all)</th>\n",
       "      <th>Tau (all)</th>\n",
       "      <th>Rho (single)</th>\n",
       "      <th>Tau (single)</th>\n",
       "      <th>Rho (multi)</th>\n",
       "      <th>Tau (multi)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frequency</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complex, ap/ap</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complex, c/c</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>complex, ap/c</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pca100_text, ap/ap</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pca100_text, c/c</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pca100_text, ap/c</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text1024, ap/ap</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>text1024, c/c</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>text1024, ap/c</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LP-profile_transe</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LP-transe</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.391</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LP-complex</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LP-profile-transe</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>transe, ap/ap</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>transe, c/c</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>transe, ap/c</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>profile-transe, ap/ap</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>profile-transe, c/c</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>profile-transe, ap/c</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>H, ap/ap</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>H, c/c</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>H, ap/c</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A, ap/ap</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A, c/c</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A, ap/c</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S, ap/ap</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S, c/c</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S, ap/c</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>profile-complex, ap/ap</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>profile-complex, c/c</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>profile-complex, ap/c</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Rho (qnode) Tau (qnode) Rho (num) Tau (num)  \\\n",
       "0                   random      -0.003      -0.002     0.024     0.019   \n",
       "1                frequency       0.043       0.055     0.134     0.129   \n",
       "2           complex, ap/ap       0.540       0.446     0.415     0.364   \n",
       "3             complex, c/c       0.556       0.468     0.455     0.382   \n",
       "4            complex, ap/c       0.551       0.457     0.355     0.271   \n",
       "5       pca100_text, ap/ap       0.476       0.411     0.424     0.340   \n",
       "6         pca100_text, c/c       0.490       0.411     0.424     0.340   \n",
       "7        pca100_text, ap/c       0.431       0.361     0.297     0.247   \n",
       "8          text1024, ap/ap       0.552       0.480     0.449     0.375   \n",
       "9            text1024, c/c       0.574       0.502     0.490     0.394   \n",
       "10          text1024, ap/c       0.552       0.480     0.515     0.429   \n",
       "11       LP-profile_transe       0.190       0.141     0.099     0.074   \n",
       "12               LP-transe       0.442       0.391         -         -   \n",
       "13              LP-complex       0.475       0.413         -         -   \n",
       "14       LP-profile-transe       0.190       0.141     0.099     0.074   \n",
       "15           transe, ap/ap       0.620       0.513     0.353     0.288   \n",
       "16             transe, c/c       0.638       0.526     0.326     0.228   \n",
       "17            transe, ap/c       0.618       0.515     0.274     0.191   \n",
       "18   profile-transe, ap/ap       0.426       0.382     0.211     0.137   \n",
       "19     profile-transe, c/c       0.421       0.382     0.211     0.137   \n",
       "20    profile-transe, ap/c       0.450       0.414     0.211     0.137   \n",
       "21                H, ap/ap       0.574       0.493     0.308     0.255   \n",
       "22                  H, c/c       0.594       0.505     0.401     0.348   \n",
       "23                 H, ap/c       0.570       0.469     0.392     0.344   \n",
       "24                A, ap/ap       0.086       0.077     0.097     0.078   \n",
       "25                  A, c/c       0.081       0.088     0.171     0.152   \n",
       "26                 A, ap/c       0.121       0.090    -0.029    -0.015   \n",
       "27                S, ap/ap       0.029      -0.009     0.157     0.112   \n",
       "28                  S, c/c      -0.025      -0.067     0.381     0.286   \n",
       "29                 S, ap/c      -0.204      -0.195     0.361     0.271   \n",
       "30  profile-complex, ap/ap       0.429       0.381    -0.111    -0.036   \n",
       "31    profile-complex, c/c       0.429       0.381     0.056     0.075   \n",
       "32   profile-complex, ap/c       0.457       0.393    -0.004     0.004   \n",
       "\n",
       "   Rho (all) Tau (all) Rho (single) Tau (single) Rho (multi) Tau (multi)  \n",
       "0      0.003     0.003        0.023        0.019      -0.005      -0.003  \n",
       "1      0.066     0.074        0.108        0.095       0.049       0.065  \n",
       "2      0.508     0.425        0.473        0.418       0.523       0.428  \n",
       "3      0.531     0.447        0.507        0.433       0.541       0.452  \n",
       "4      0.502     0.410        0.422        0.338       0.535       0.440  \n",
       "5      0.463     0.393        0.429        0.337       0.476       0.416  \n",
       "6      0.473     0.393        0.429        0.337       0.492       0.416  \n",
       "7      0.397     0.333        0.321        0.257       0.429       0.364  \n",
       "8      0.526     0.454        0.510        0.427       0.533       0.465  \n",
       "9      0.553     0.475        0.544        0.443       0.557       0.488  \n",
       "10     0.543     0.467        0.566        0.473       0.533       0.465  \n",
       "11     0.167     0.124        0.180        0.139       0.162       0.118  \n",
       "12         -         -            -            -       0.428       0.383  \n",
       "13         -         -            -            -       0.461       0.406  \n",
       "14     0.167     0.124        0.180        0.139       0.162       0.118  \n",
       "15     0.553     0.457        0.442        0.382       0.599       0.487  \n",
       "16     0.560     0.452        0.419        0.331       0.618       0.501  \n",
       "17     0.532     0.434        0.374        0.299       0.597       0.489  \n",
       "18     0.372     0.320        0.298        0.223       0.403       0.361  \n",
       "19     0.368     0.320        0.298        0.223       0.397       0.361  \n",
       "20     0.390     0.345        0.320        0.253       0.419       0.383  \n",
       "21     0.507     0.434        0.381        0.324       0.559       0.479  \n",
       "22     0.546     0.466        0.461        0.403       0.580       0.492  \n",
       "23     0.525     0.438        0.475        0.430       0.546       0.441  \n",
       "24     0.089     0.077        0.068        0.052       0.098       0.087  \n",
       "25     0.103     0.104        0.132        0.115       0.092       0.100  \n",
       "26     0.083     0.064       -0.040       -0.028       0.134       0.102  \n",
       "27     0.061     0.021        0.017       -0.010       0.079       0.034  \n",
       "28     0.076     0.021        0.209        0.139       0.022      -0.028  \n",
       "29    -0.063    -0.079        0.192        0.127      -0.168      -0.163  \n",
       "30     0.294     0.277        0.030        0.074       0.403       0.360  \n",
       "31     0.335     0.305        0.173        0.170       0.403       0.360  \n",
       "32     0.342     0.296        0.121        0.109       0.432       0.373  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update_corr_measures(questions)\n",
    "display_avg_question_corr(question_subsets, questions[0][\"method_spearman\"])      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ae3d8",
   "metadata": {},
   "source": [
    "## Link prediction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "id": "4d634b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lp_embedding_model(base_dir, model_v_num, operator, dim):\n",
    "    relation_names_list = json.load(open(f\"{base_dir}/dynamic_rel_names.json\"))\n",
    "    entity_names_list = json.load(open(f\"{base_dir}/entity_names_all_0.json\"))\n",
    "#     print(\"creating entity-to-index dict...\")\n",
    "    entity_to_index = {}\n",
    "    for i, entity in enumerate(entity_names_list):\n",
    "        entity_to_index[entity] = i\n",
    "\n",
    "#     print(\"creating relation-to-index dict...\")\n",
    "    rel_index = {}\n",
    "    for i, rel in enumerate(relation_names_list):\n",
    "        rel_index[rel] = i\n",
    "\n",
    "    prop_count = len(relation_names_list)\n",
    "\n",
    "    # operators\n",
    "    if operator == \"complex_diagonal\":\n",
    "        operator_lhs = ComplexDiagonalDynamicOperator(dim, prop_count)\n",
    "        operator_rhs = ComplexDiagonalDynamicOperator(dim, prop_count)\n",
    "    elif operator == \"translation\":\n",
    "        operator_lhs = TranslationDynamicOperator(dim, prop_count)\n",
    "        operator_rhs = TranslationDynamicOperator(dim, prop_count)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    with h5py.File(f\"{base_dir}/model/model.{model_v_num}.h5\", \"r\") as hf:\n",
    "        if operator == \"complex_diagonal\":\n",
    "            operator_state_dict_lhs = {\n",
    "                \"real\": torch.from_numpy(hf[\"model/relations/0/operator/lhs/real\"][...]),\n",
    "                \"imag\": torch.from_numpy(hf[\"model/relations/0/operator/lhs/imag\"][...]),\n",
    "            }\n",
    "            operator_state_dict_rhs = {\n",
    "                \"real\": torch.from_numpy(hf[\"model/relations/0/operator/rhs/real\"][...]),\n",
    "                \"imag\": torch.from_numpy(hf[\"model/relations/0/operator/rhs/imag\"][...]),\n",
    "            }\n",
    "        elif operator == \"translation\":\n",
    "            operator_state_dict_lhs = {\n",
    "                \"translations\": torch.from_numpy(hf[\"model/relations/0/operator/lhs/translations\"][...]),\n",
    "            }\n",
    "            operator_state_dict_rhs = {\n",
    "                \"translations\": torch.from_numpy(hf[\"model/relations/0/operator/rhs/translations\"][...]),\n",
    "            }\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "#     print(\"loading operator state...\")\n",
    "    operator_lhs.load_state_dict(operator_state_dict_lhs)\n",
    "    operator_rhs.load_state_dict(operator_state_dict_rhs)\n",
    "        \n",
    "    return [operator_lhs, operator_rhs, entity_to_index, rel_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "id": "42079730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: -2.0973997116088867\n",
      "German: -3.60689640045166\n",
      "Russian: -11.97774600982666\n",
      "Swedish: 0.3592963218688965\n",
      "Spanish: 7.68614387512207\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "def get_lp_scores(src_ent, dest_ents, edge, entity_to_index, rel_index,\n",
    "                  base_dir, model_v_num, dim, comparator, operator, is_lhs):\n",
    "\n",
    "    src_offset = entity_to_index[src_ent]\n",
    "    dest_offsets = [[entity_to_index[e] for e in synonyms] for synonyms in dest_ents]\n",
    "    # src_offset = entity_names_list.index(src_ent)\n",
    "    # dest_offsets = [entity_names_list.index(e) for e in dest_ents]\n",
    "\n",
    "    # Load the embeddings\n",
    "    with h5py.File(f\"{base_dir}/model/embeddings_all_0.{model_v_num}.h5\", \"r\") as hf:\n",
    "        src_embedding = torch.from_numpy(hf[\"embeddings\"][src_offset, :])\n",
    "        dest_embeddings = [torch.stack([torch.from_numpy(hf[\"embeddings\"][syn_offset, :]) for syn_offset in synonym_offsets]) for synonym_offsets in dest_offsets]\n",
    "    \n",
    "    # Calculate the scores\n",
    "    scores = []\n",
    "    for syn_embeddings in dest_embeddings:\n",
    "        if is_lhs:\n",
    "            syn_scores, _, _ = comparator(\n",
    "            comparator.prepare(\n",
    "                operator(\n",
    "                    src_embedding,\n",
    "                    torch.tensor(rel_index[edge]),\n",
    "                ).expand(1, len(syn_embeddings), dim),\n",
    "            ),\n",
    "            comparator.prepare(syn_embeddings.view(1, len(syn_embeddings), dim)),\n",
    "            torch.empty(1, 0, dim), # Left-hand side negatives, not needed\n",
    "            torch.empty(1, 0, dim), # Right-hand side negatives, not needed\n",
    "            )\n",
    "        else:\n",
    "            syn_scores, _, _ = comparator(\n",
    "                comparator.prepare(src_embedding.view(1, 1, dim)).expand(1, len(syn_embeddings), dim),\n",
    "                comparator.prepare(\n",
    "                    operator(\n",
    "                        syn_embeddings,\n",
    "                        torch.tensor([rel_index[edge]]).expand(len(syn_embeddings)),\n",
    "                    ).view(1, len(syn_embeddings), dim),\n",
    "                ),\n",
    "                torch.empty(1, 0, dim), # Left-hand side negatives, not needed\n",
    "                torch.empty(1, 0, dim), # Right-hand side negatives, not needed\n",
    "            )\n",
    "        scores.append(np.mean(syn_scores.detach().numpy()))\n",
    "    return scores\n",
    "\n",
    "q = questions[0]\n",
    "src_ent = q[\"entity\"]\n",
    "dest_ents = [ans[\"qnodes\"] for ans in q[\"answers\"]]\n",
    "edge = q[\"property\"]\n",
    "scores = get_lp_scores(src_ent, dest_ents, edge, entity_to_index, rel_index,\n",
    "                  base_dir, model_v_num, dim, comparator, operator_lhs, is_lhs=True)\n",
    "for i in range(len(dest_ents)):\n",
    "    print(f'{q[\"answers\"][i][\"lexicalized\"]}: {1-scores[i]}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "id": "485bf9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transe\n",
      "\tP1971 not in embeddings. Skipping question: How many children does Arnold Schwarzenegger have?\n",
      "\tP2067 not in embeddings. Skipping question: What is Donald Trump's mass in pounds circa. 2019?\n",
      "\tP2250 not in embeddings. Skipping question: What is the life expectancy in years of Australia circa. 2016?\n",
      "\tP3001 not in embeddings. Skipping question: What is the retirement age in Colombia? The answer for either men or women will be accepted.\n",
      "\tP2927 not in embeddings. Skipping question: What percentage of the territory of Canada inside its coast line and international boundaries is water?\n",
      "\tP2139 not in embeddings. Skipping question: What was the total revenue in euros of the business \"Adidas\" circa. 2014?\n",
      "profile-transe\n",
      "complex\n",
      "\tP1971 not in embeddings. Skipping question: How many children does Arnold Schwarzenegger have?\n",
      "\tP2067 not in embeddings. Skipping question: What is Donald Trump's mass in pounds circa. 2019?\n",
      "\tP2250 not in embeddings. Skipping question: What is the life expectancy in years of Australia circa. 2016?\n",
      "\tP3001 not in embeddings. Skipping question: What is the retirement age in Colombia? The answer for either men or women will be accepted.\n",
      "\tP2927 not in embeddings. Skipping question: What percentage of the territory of Canada inside its coast line and international boundaries is water?\n",
      "\tP2139 not in embeddings. Skipping question: What was the total revenue in euros of the business \"Adidas\" circa. 2014?\n",
      "profile-complex\n"
     ]
    }
   ],
   "source": [
    "comparators = {\"dot\": DotComparator(), \"cos\": CosComparator(), \"l2\": L2Comparator()}\n",
    "\n",
    "for lp_emb_name, model_info_dict in lp_embedding_models_info.items():\n",
    "    # following if block will avoid recomputing already-computed methods\n",
    "#     if f\"LP-{lp_emb_name}\" in questions[0][\"answers\"][0][\"method_surprise_scores\"]:\n",
    "#         continue\n",
    "            \n",
    "    print(lp_emb_name)\n",
    "    # load lp embedding model\n",
    "    base_dir = model_info_dict[\"base_dir\"]\n",
    "    model_v_num = model_info_dict[\"model_v_num\"]\n",
    "    operator = model_info_dict[\"operator\"]\n",
    "    dim = model_info_dict[\"dim\"]\n",
    "    [operator_lhs, operator_rhs, entity_to_index, rel_index] = \\\n",
    "        load_lp_embedding_model(base_dir, model_v_num, operator, dim)\n",
    "    for q in questions:\n",
    "        src_ent = q[\"entity\"]\n",
    "        edge = q[\"property\"]\n",
    "        if \"profile\" in lp_emb_name:\n",
    "            edge += \"_profile\"\n",
    "        if edge not in rel_index:\n",
    "            print(f'\\t{edge} not in embeddings. Skipping question: {q[\"lexicalized\"]}')\n",
    "            continue\n",
    "        value_key = \"fact_ids\" if \"profile\" in lp_emb_name else \"qnodes\"\n",
    "        dest_ents = [ans[value_key] for ans in q[\"answers\"]]\n",
    "        # get LP scores for each comparator and lhs/rhs\n",
    "        for comparator_name, comparator in comparators.items():\n",
    "            lhs_scores = get_lp_scores(src_ent, dest_ents, edge, entity_to_index, rel_index,\n",
    "                                       base_dir, model_v_num, dim, comparator, operator_lhs, is_lhs=True)\n",
    "            rhs_scores = get_lp_scores(src_ent, dest_ents, edge, entity_to_index, rel_index,\n",
    "                                       base_dir, model_v_num, dim, comparator, operator_rhs, is_lhs=False)\n",
    "            # save method scores for each answer\n",
    "            for i, answer in enumerate(q[\"answers\"]):\n",
    "                answer[\"method_surprise_scores\"][f\"LP-{lp_emb_name}-lhs-{comparator_name}\"] = 1 - lhs_scores[i]\n",
    "                answer[\"method_surprise_scores\"][f\"LP-{lp_emb_name}-rhs-{comparator_name}\"] = 1 - rhs_scores[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51b2a5",
   "metadata": {},
   "source": [
    "## view avg correlation in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "id": "c37edfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Rho (qnode)</th>\n",
       "      <th>Tau (qnode)</th>\n",
       "      <th>Rho (num)</th>\n",
       "      <th>Tau (num)</th>\n",
       "      <th>Rho (all)</th>\n",
       "      <th>Tau (all)</th>\n",
       "      <th>Rho (single)</th>\n",
       "      <th>Tau (single)</th>\n",
       "      <th>Rho (multi)</th>\n",
       "      <th>Tau (multi)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frequency</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complex, ap/ap</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complex, c/c</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>complex, ap/c</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pca100_text, ap/ap</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pca100_text, c/c</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pca100_text, ap/c</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text1024, ap/ap</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>text1024, c/c</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>text1024, ap/c</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>transe, ap/ap</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>transe, c/c</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transe, ap/c</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>profile-transe, ap/ap</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>profile-transe, c/c</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>profile-transe, ap/c</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>H, ap/ap</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>H, c/c</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>H, ap/c</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A, ap/ap</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A, c/c</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A, ap/c</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S, ap/ap</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S, c/c</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S, ap/c</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>profile-complex, ap/ap</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>profile-complex, c/c</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>profile-complex, ap/c</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LP-transe-lhs-dot</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.335</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LP-transe-rhs-dot</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LP-transe-lhs-cos</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.391</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LP-transe-rhs-cos</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.336</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LP-profile-transe-lhs-dot</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LP-profile-transe-rhs-dot</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LP-profile-transe-lhs-cos</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LP-profile-transe-rhs-cos</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LP-complex-lhs-dot</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.424</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LP-complex-rhs-dot</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LP-complex-lhs-cos</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LP-complex-rhs-cos</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LP-profile-complex-lhs-dot</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>LP-profile-complex-rhs-dot</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LP-profile-complex-lhs-cos</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LP-profile-complex-rhs-cos</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>LP-transe-lhs-l2</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>LP-transe-rhs-l2</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>LP-profile-transe-lhs-l2</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LP-profile-transe-rhs-l2</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>LP-complex-lhs-l2</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.379</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>LP-complex-rhs-l2</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>LP-profile-complex-lhs-l2</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>LP-profile-complex-rhs-l2</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Rho (qnode) Tau (qnode) Rho (num) Tau (num)  \\\n",
       "0                       random      -0.003      -0.002     0.024     0.019   \n",
       "1                    frequency       0.043       0.055     0.134     0.129   \n",
       "2               complex, ap/ap       0.540       0.446     0.415     0.364   \n",
       "3                 complex, c/c       0.556       0.468     0.455     0.382   \n",
       "4                complex, ap/c       0.551       0.457     0.355     0.271   \n",
       "5           pca100_text, ap/ap       0.476       0.411     0.424     0.340   \n",
       "6             pca100_text, c/c       0.490       0.411     0.424     0.340   \n",
       "7            pca100_text, ap/c       0.431       0.361     0.297     0.247   \n",
       "8              text1024, ap/ap       0.552       0.480     0.449     0.375   \n",
       "9                text1024, c/c       0.574       0.502     0.490     0.394   \n",
       "10              text1024, ap/c       0.552       0.480     0.515     0.429   \n",
       "11               transe, ap/ap       0.620       0.513     0.353     0.288   \n",
       "12                 transe, c/c       0.638       0.526     0.326     0.228   \n",
       "13                transe, ap/c       0.618       0.515     0.274     0.191   \n",
       "14       profile-transe, ap/ap       0.426       0.382     0.211     0.137   \n",
       "15         profile-transe, c/c       0.421       0.382     0.211     0.137   \n",
       "16        profile-transe, ap/c       0.450       0.414     0.211     0.137   \n",
       "17                    H, ap/ap       0.574       0.493     0.308     0.255   \n",
       "18                      H, c/c       0.594       0.505     0.401     0.348   \n",
       "19                     H, ap/c       0.570       0.469     0.392     0.344   \n",
       "20                    A, ap/ap       0.086       0.077     0.097     0.078   \n",
       "21                      A, c/c       0.081       0.088     0.171     0.152   \n",
       "22                     A, ap/c       0.121       0.090    -0.029    -0.015   \n",
       "23                    S, ap/ap       0.029      -0.009     0.157     0.112   \n",
       "24                      S, c/c      -0.025      -0.067     0.381     0.286   \n",
       "25                     S, ap/c      -0.204      -0.195     0.361     0.271   \n",
       "26      profile-complex, ap/ap       0.429       0.381    -0.111    -0.036   \n",
       "27        profile-complex, c/c       0.429       0.381     0.056     0.075   \n",
       "28       profile-complex, ap/c       0.457       0.393    -0.004     0.004   \n",
       "29           LP-transe-lhs-dot       0.383       0.335         -         -   \n",
       "30           LP-transe-rhs-dot       0.383       0.347         -         -   \n",
       "31           LP-transe-lhs-cos       0.442       0.391         -         -   \n",
       "32           LP-transe-rhs-cos       0.372       0.336         -         -   \n",
       "33   LP-profile-transe-lhs-dot       0.227       0.165     0.376     0.253   \n",
       "34   LP-profile-transe-rhs-dot       0.224       0.165     0.289     0.265   \n",
       "35   LP-profile-transe-lhs-cos       0.190       0.141     0.099     0.074   \n",
       "36   LP-profile-transe-rhs-cos       0.246       0.211     0.422     0.376   \n",
       "37          LP-complex-lhs-dot       0.481       0.424         -         -   \n",
       "38          LP-complex-rhs-dot       0.419       0.357         -         -   \n",
       "39          LP-complex-lhs-cos       0.475       0.413         -         -   \n",
       "40          LP-complex-rhs-cos       0.360       0.300         -         -   \n",
       "41  LP-profile-complex-lhs-dot       0.422       0.368     0.058     0.062   \n",
       "42  LP-profile-complex-rhs-dot       0.297       0.256     0.159     0.142   \n",
       "43  LP-profile-complex-lhs-cos       0.355       0.301     0.076     0.024   \n",
       "44  LP-profile-complex-rhs-cos       0.392       0.346     0.219     0.180   \n",
       "45            LP-transe-lhs-l2       0.202       0.188         -         -   \n",
       "46            LP-transe-rhs-l2       0.148       0.142         -         -   \n",
       "47    LP-profile-transe-lhs-l2       0.090       0.083     0.030     0.072   \n",
       "48    LP-profile-transe-rhs-l2       0.222       0.185     0.349     0.282   \n",
       "49           LP-complex-lhs-l2       0.439       0.379         -         -   \n",
       "50           LP-complex-rhs-l2       0.048       0.042         -         -   \n",
       "51   LP-profile-complex-lhs-l2       0.251       0.209    -0.032    -0.068   \n",
       "52   LP-profile-complex-rhs-l2       0.092       0.084    -0.222    -0.208   \n",
       "\n",
       "   Rho (all) Tau (all) Rho (single) Tau (single) Rho (multi) Tau (multi)  \n",
       "0      0.003     0.003        0.023        0.019      -0.005      -0.003  \n",
       "1      0.066     0.074        0.108        0.095       0.049       0.065  \n",
       "2      0.508     0.425        0.473        0.418       0.523       0.428  \n",
       "3      0.531     0.447        0.507        0.433       0.541       0.452  \n",
       "4      0.502     0.410        0.422        0.338       0.535       0.440  \n",
       "5      0.463     0.393        0.429        0.337       0.476       0.416  \n",
       "6      0.473     0.393        0.429        0.337       0.492       0.416  \n",
       "7      0.397     0.333        0.321        0.257       0.429       0.364  \n",
       "8      0.526     0.454        0.510        0.427       0.533       0.465  \n",
       "9      0.553     0.475        0.544        0.443       0.557       0.488  \n",
       "10     0.543     0.467        0.566        0.473       0.533       0.465  \n",
       "11     0.553     0.457        0.442        0.382       0.599       0.487  \n",
       "12     0.560     0.452        0.419        0.331       0.618       0.501  \n",
       "13     0.532     0.434        0.374        0.299       0.597       0.489  \n",
       "14     0.372     0.320        0.298        0.223       0.403       0.361  \n",
       "15     0.368     0.320        0.298        0.223       0.397       0.361  \n",
       "16     0.390     0.345        0.320        0.253       0.419       0.383  \n",
       "17     0.507     0.434        0.381        0.324       0.559       0.479  \n",
       "18     0.546     0.466        0.461        0.403       0.580       0.492  \n",
       "19     0.525     0.438        0.475        0.430       0.546       0.441  \n",
       "20     0.089     0.077        0.068        0.052       0.098       0.087  \n",
       "21     0.103     0.104        0.132        0.115       0.092       0.100  \n",
       "22     0.083     0.064       -0.040       -0.028       0.134       0.102  \n",
       "23     0.061     0.021        0.017       -0.010       0.079       0.034  \n",
       "24     0.076     0.021        0.209        0.139       0.022      -0.028  \n",
       "25    -0.063    -0.079        0.192        0.127      -0.168      -0.163  \n",
       "26     0.294     0.277        0.030        0.074       0.403       0.360  \n",
       "27     0.335     0.305        0.173        0.170       0.403       0.360  \n",
       "28     0.342     0.296        0.121        0.109       0.432       0.373  \n",
       "29         -         -            -            -       0.366       0.324  \n",
       "30         -         -            -            -       0.367       0.336  \n",
       "31         -         -            -            -       0.428       0.383  \n",
       "32         -         -            -            -       0.355       0.324  \n",
       "33     0.264     0.187        0.417        0.292       0.201       0.144  \n",
       "34     0.240     0.190        0.343        0.303       0.198       0.144  \n",
       "35     0.167     0.124        0.180        0.139       0.162       0.118  \n",
       "36     0.290     0.252        0.457        0.398       0.221       0.192  \n",
       "37         -         -            -            -       0.467       0.418  \n",
       "38         -         -            -            -       0.402       0.347  \n",
       "39         -         -            -            -       0.461       0.406  \n",
       "40         -         -            -            -       0.339       0.286  \n",
       "41     0.331     0.292        0.175        0.158       0.396       0.347  \n",
       "42     0.262     0.228        0.232        0.197       0.275       0.240  \n",
       "43     0.286     0.232        0.189        0.126       0.325       0.276  \n",
       "44     0.348     0.304        0.283        0.229       0.375       0.335  \n",
       "45         -         -            -            -       0.190       0.180  \n",
       "46         -         -            -            -       0.115       0.119  \n",
       "47     0.075     0.080       -0.062       -0.014       0.131       0.119  \n",
       "48     0.254     0.209        0.292        0.227       0.238       0.202  \n",
       "49         -         -            -            -       0.423       0.371  \n",
       "50         -         -            -            -      -0.001       0.001  \n",
       "51     0.180     0.140        0.098        0.047       0.215       0.178  \n",
       "52     0.014     0.011       -0.073       -0.073       0.049       0.045  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update_corr_measures(questions)\n",
    "display_avg_question_corr(question_subsets, questions[0][\"method_spearman\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee7437",
   "metadata": {},
   "source": [
    "## Auto-ML supervised link prediction models\n",
    "Hayden-todo: update header description here if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaaa8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hayden-todo: fill this out\n",
    "def get_automl_lp_top1_emb(entity, prop):\n",
    "    \"\"\"\n",
    "    get embedding predictions for the object the given subject-property pair\n",
    "        entity: qnode (string)\n",
    "        prop: pnode (string)\n",
    "        return: the embedding of the top 1 prediction\n",
    "    \"\"\"\n",
    "    pass\n",
    "    \n",
    "# Hayden-todo: fill this out\n",
    "def get_automl_emb(obj):\n",
    "    \"\"\"\n",
    "    get embeddings for the target object of each fact.\n",
    "        obj: qnode (string)\n",
    "        return: the embedding for the given entity obj\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3e74a",
   "metadata": {},
   "source": [
    "Hayden-todo: after filling out the above functions, run the below cell to compute scores for your method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c4e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in questions:\n",
    "    src_ent = q[\"entity\"]\n",
    "    edge = q[\"property\"]\n",
    "    dest_ents = [ans[qnodes] for ans in q[\"answers\"]]\n",
    "    \n",
    "    # get embedding prediction question\n",
    "    automl_pred_emb = get_automl_lp_top1_emb(src_ent, edge)\n",
    "    \n",
    "    # get scores for each answer in the question\n",
    "    scores = []\n",
    "    for syn_ents in dest_ents: # each answer can have more than one synonym qnode\n",
    "        # get embeddings for each target object synonym\n",
    "        automl_target_embs = [get_automl_emb(obj) for obj in syn_ents]\n",
    "        syn_scores = [distance.cosine(pre, target) for pred in automl_target_embs]\n",
    "        scores.append(np.mean(syn_scores))\n",
    "\n",
    "   # save method scores for each answer\n",
    "    for i, answer in enumerate(q[\"answers\"]):\n",
    "        answer[\"method_surprise_scores\"][\"automl-LP\"] = scores[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b59088",
   "metadata": {},
   "source": [
    "## view avg correlation in question\n",
    "Hayden-todo: run below cell to view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_corr_measures(questions)\n",
    "display_avg_question_corr(question_subsets, questions[0][\"method_spearman\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cca874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf1fa480",
   "metadata": {},
   "source": [
    "### Other evaluationg methods besides avg correlation within each question...\n",
    "Pausing on this for now. Just tried some statistical method\n",
    "#### Correlation of facts across all questions (NO normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "925536e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation across all facts (no normalization)\n",
      "\tmulti-answer questions only\n",
      "\t\tSpearman: 0.274, pval=0.011\n",
      "\t\tKT: 0.182, pval=0.016\n",
      "\tsingle-answer questions only\n",
      "\t\tSpearman: 0.294, pval=0.097\n",
      "\t\tKT: 0.213, pval=0.092\n",
      "\tall questions\n",
      "\t\tSpearman: 0.142, pval=0.125\n",
      "\t\tKT: 0.086, pval=0.175\n"
     ]
    }
   ],
   "source": [
    "max_count = 26 # 26 test takers\n",
    "emb_name = 'text1024'\n",
    "surprise_metric = 'distance(avg pairwise)/dispersion(avg pairwise)'\n",
    "single_ans_gts = []\n",
    "single_ans_preds = []\n",
    "multi_ans_gts = []\n",
    "multi_ans_preds = []\n",
    "for q in questions:\n",
    "    answers = list(q[\"pred_counts\"].keys())\n",
    "    if q[\"single_answer\"]:\n",
    "        single_ans_gts.extend([max_count - count for count in q[\"pred_counts\"].values()])\n",
    "        single_ans_preds.extend([q[\"ans_to_surprise_metrics_dict\"][ans][emb_name][surprise_metric] for ans in answers])\n",
    "    else:\n",
    "        multi_ans_gts.extend([max_count - count for count in q[\"pred_counts\"].values()])\n",
    "        multi_ans_preds.extend([q[\"ans_to_surprise_metrics_dict\"][ans][emb_name][surprise_metric] for ans in answers])\n",
    "\n",
    "print(\"correlation across all facts (no normalization)\")\n",
    "print(\"\\tmulti-answer questions only\")\n",
    "rho, rho_pval = spearmanr(multi_ans_gts, multi_ans_preds)\n",
    "tau, tau_pval = kendalltau(multi_ans_gts, multi_ans_preds)\n",
    "print(f\"\\t\\tSpearman: {rho:.3f}, pval={rho_pval:.3f}\")\n",
    "print(f\"\\t\\tKT: {tau:.3f}, pval={tau_pval:.3f}\")\n",
    "print(\"\\tsingle-answer questions only\")\n",
    "rho, rho_pval = spearmanr(single_ans_gts, single_ans_preds)\n",
    "tau, tau_pval = kendalltau(single_ans_gts, single_ans_preds)\n",
    "print(f\"\\t\\tSpearman: {rho:.3f}, pval={rho_pval:.3f}\")\n",
    "print(f\"\\t\\tKT: {tau:.3f}, pval={tau_pval:.3f}\")\n",
    "print(\"\\tall questions\")\n",
    "rho, rho_pval = spearmanr(multi_ans_gts + single_ans_gts, multi_ans_preds + single_ans_preds)\n",
    "tau, tau_pval = kendalltau(multi_ans_gts + single_ans_gts, multi_ans_preds + single_ans_preds)\n",
    "print(f\"\\t\\tSpearman: {rho:.3f}, pval={rho_pval:.3f}\")\n",
    "print(f\"\\t\\tKT: {tau:.3f}, pval={tau_pval:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65afa180",
   "metadata": {},
   "source": [
    "**Hypothesis:** Using # of people who chose the answer to infer surprise/unexpectedness will not be directly comparable between single and multi-answer questions. In multi-answer questions, every answer can have up to the total number of participants choose it, making it similar to if we had asked each answer as a separate true/false question. Meanwhile, in single-answer questions, picking one answer means the participant cannot choose any other answers. This could mean that even if no answer is very surprising, some answers may have very few people choose it simply because there was a similar answer that seemed like a safer bet.\n",
    "\n",
    "**observation:** The above result supports this hypothesis.\n",
    "\n",
    "**What to do about this:** Either evaluate single and multi answers separately or come up with another surprise-score-inference method that is more comparable across the two kinds of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4476e97a",
   "metadata": {},
   "source": [
    "Let's check if the effect we are seeing above is due to the decrease in number of facts being compared..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "e20babd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(single_ans_gts): 33\n",
      "len(multi_ans_gts): 85\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(single_ans_gts): {len(single_ans_gts)}\")\n",
    "print(f\"len(multi_ans_gts): {len(multi_ans_gts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "66c45ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=-0.03149116526040072, pvalue=0.8018067539647361)"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(multi_ans_gts[:33] + single_ans_gts, multi_ans_preds[:33] + single_ans_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "3bb73262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.17886051056359697, pvalue=0.3192897690462346)"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(multi_ans_gts[:33], multi_ans_preds[:33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "3de1701f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.2939105369545495, pvalue=0.09687748220540489)"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(single_ans_gts,single_ans_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ca805",
   "metadata": {},
   "source": [
    "Safe to say it is not due to decrease in size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce29500",
   "metadata": {},
   "source": [
    "#### Correlation of facts across all questions (with normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce0937a",
   "metadata": {},
   "source": [
    "Start by gathering samples for each class we are dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "839befdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ent_class_to_sample = {}\n",
    "# for q in tqdm(questions):\n",
    "#     ent_class = q[\"class\"]\n",
    "#     if ent_class not in ent_class_to_sample:\n",
    "#         ent_class_to_sample[ent_class] = get_ents_of_type(\"\", ent_class, limit=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25c01c",
   "metadata": {},
   "source": [
    "Now we can compute dispersion of each class once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7667cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_dispersion_dict = {}\n",
    "# for ent_class, sample_ents in tqdm(ent_class_to_sample.items()):\n",
    "#     class_dispersion_dict[ent_class] = compute_avg_pairwise_dist_in_sample(sample_ents, embedding_dict, pariwise_sample=10000)\n",
    "\n",
    "# compute_avg_dist_from_ent_to_sample(ent, sample_ents, embedding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3bff35",
   "metadata": {},
   "source": [
    "ignore above, changed functions to use lru cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "ea937708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for q in tqdm(questions):\n",
    "    q[\"class_surprise_metrics_dict\"] = compute_surprise_metrics_sampling_by_type(q[\"entity\"], q[\"class\"], embedding_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "3bf8d520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation across all facts (WITH normalization)\n",
      "\tmulti-answer questions only\n",
      "\t\tSpearman: 0.354, pval=0.001\n",
      "\t\tKT: 0.246, pval=0.001\n",
      "\tsingle-answer questions only\n",
      "\t\tSpearman: 0.191, pval=0.287\n",
      "\t\tKT: 0.150, pval=0.235\n",
      "\tall questions\n",
      "\t\tSpearman: 0.186, pval=0.044\n",
      "\t\tKT: 0.122, pval=0.055\n"
     ]
    }
   ],
   "source": [
    "max_count = 26 # 26 test takers\n",
    "emb_name = 'text1024'\n",
    "surprise_metric = 'distance(avg pairwise)/dispersion(avg pairwise)'\n",
    "single_ans_gts = []\n",
    "single_ans_preds = []\n",
    "multi_ans_gts = []\n",
    "multi_ans_preds = []\n",
    "for q in questions:\n",
    "    answers = list(q[\"pred_counts\"].keys())\n",
    "    ans_surprise_gts.extend([max_count - count for count in q[\"pred_counts\"].values()])\n",
    "    q_ans_surprise_preds = []\n",
    "    surprise_of_ent_in_class = q[\"class_surprise_metrics_dict\"][emb_name][surprise_metric]\n",
    "    for ans in answers:\n",
    "        unnormalized_surprise = q[\"ans_to_surprise_metrics_dict\"][ans][emb_name][surprise_metric]\n",
    "        q_ans_surprise_preds.append(unnormalized_surprise / surprise_of_ent_in_class)\n",
    "    if q[\"single_answer\"]:\n",
    "        single_ans_gts.extend([max_count - count for count in q[\"pred_counts\"].values()])\n",
    "        single_ans_preds.extend(q_ans_surprise_preds)\n",
    "    else:\n",
    "        multi_ans_gts.extend([max_count - count for count in q[\"pred_counts\"].values()])\n",
    "        multi_ans_preds.extend(q_ans_surprise_preds)\n",
    "\n",
    "print(\"correlation across all facts (WITH normalization)\")\n",
    "print(\"\\tmulti-answer questions only\")\n",
    "rho, rho_pval = spearmanr(multi_ans_gts, multi_ans_preds)\n",
    "tau, tau_pval = kendalltau(multi_ans_gts, multi_ans_preds)\n",
    "print(f\"\\t\\tSpearman: {rho:.3f}, pval={rho_pval:.3f}\")\n",
    "print(f\"\\t\\tKT: {tau:.3f}, pval={tau_pval:.3f}\")\n",
    "print(\"\\tsingle-answer questions only\")\n",
    "rho, rho_pval = spearmanr(single_ans_gts, single_ans_preds)\n",
    "tau, tau_pval = kendalltau(single_ans_gts, single_ans_preds)\n",
    "print(f\"\\t\\tSpearman: {rho:.3f}, pval={rho_pval:.3f}\")\n",
    "print(f\"\\t\\tKT: {tau:.3f}, pval={tau_pval:.3f}\")\n",
    "print(\"\\tall questions\")\n",
    "rho, rho_pval = spearmanr(multi_ans_gts + single_ans_gts, multi_ans_preds + single_ans_preds)\n",
    "tau, tau_pval = kendalltau(multi_ans_gts + single_ans_gts, multi_ans_preds + single_ans_preds)\n",
    "print(f\"\\t\\tSpearman: {rho:.3f}, pval={rho_pval:.3f}\")\n",
    "print(f\"\\t\\tKT: {tau:.3f}, pval={tau_pval:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd5c0c",
   "metadata": {},
   "source": [
    "**Observation:** As I expected, normalization helps with comparing facts about different entities when looking at multi-answer questions. However, it appears to hurt on the single answer questions. Why could this be?? We do have a much larger p-value for the single answer correlation here, so maybe it is by chance.\n",
    "\n",
    "**Note** I do not think we can say that normalization helps in general here since the increase in correlation on \"all-questions\" could be due to the higher number of multi-answer question facts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5719c53c",
   "metadata": {},
   "source": [
    "Look at what normalized values look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "b528589b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Singer-songwriter</th>\n",
       "      <th>Dancer</th>\n",
       "      <th>Entrepreneur</th>\n",
       "      <th>Model</th>\n",
       "      <th>Voice Actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Singer-songwriter Dancer Entrepreneur Model Voice Actor\n",
       "0      gt surprise                 1      7            9    11          14\n",
       "1    pred surprise              1.48   1.32         1.60  1.12        1.47\n",
       "2  normalized pred              1.19   1.06         1.28  0.90        1.18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: -0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Painter</th>\n",
       "      <th>Engineer</th>\n",
       "      <th>Chemist</th>\n",
       "      <th>Zoologist</th>\n",
       "      <th>Diplomat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Painter Engineer Chemist Zoologist Diplomat\n",
       "0      gt surprise       0        5      14        19       20\n",
       "1    pred surprise    1.66     1.17    1.32      1.36     1.21\n",
       "2  normalized pred    1.66     1.17    1.32      1.36     1.22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: -0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>&gt; 240</th>\n",
       "      <th>&gt; 210 and &lt;= 240</th>\n",
       "      <th>&gt; 195 and &lt;= 210</th>\n",
       "      <th>&gt; 1 and &lt;= 181</th>\n",
       "      <th>&gt; 181 and &lt;= 195</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   > 240 > 210 and <= 240 > 195 and <= 210 > 1 and <= 181  \\\n",
       "0      gt surprise    15               15               22             26   \n",
       "1    pred surprise  2.82             1.39             1.38           1.65   \n",
       "2  normalized pred  2.01             0.99             0.99           1.18   \n",
       "\n",
       "  > 181 and <= 195  \n",
       "0               26  \n",
       "1             1.45  \n",
       "2             1.03  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Amateur Wrestling</th>\n",
       "      <th>Boxing</th>\n",
       "      <th>Rugby</th>\n",
       "      <th>Baseball</th>\n",
       "      <th>American Football</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Amateur Wrestling Boxing Rugby Baseball American Football\n",
       "0      gt surprise                 8     17    22       23                24\n",
       "1    pred surprise              4.30   2.17  2.57     2.73              3.74\n",
       "2  normalized pred              3.85   1.94  2.30     2.44              3.35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Republican Party</th>\n",
       "      <th>Democratic Party</th>\n",
       "      <th>Communist Party of the Soviet Union</th>\n",
       "      <th>National Socialist German Workers' Party</th>\n",
       "      <th>Social Democratic Party of Germany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Republican Party Democratic Party  \\\n",
       "0      gt surprise                0               10   \n",
       "1    pred surprise             1.60             1.70   \n",
       "2  normalized pred             1.14             1.21   \n",
       "\n",
       "  Communist Party of the Soviet Union  \\\n",
       "0                                  26   \n",
       "1                                1.76   \n",
       "2                                1.25   \n",
       "\n",
       "  National Socialist German Workers' Party Social Democratic Party of Germany  \n",
       "0                                       26                                 26  \n",
       "1                                     1.52                               1.83  \n",
       "2                                     1.08                               1.31  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.3354101966249684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Basketball Player</th>\n",
       "      <th>Television Actor</th>\n",
       "      <th>Writer</th>\n",
       "      <th>Screenwriter</th>\n",
       "      <th>Researcher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.48</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Basketball Player Television Actor Writer Screenwriter  \\\n",
       "0      gt surprise                 0               13     22           23   \n",
       "1    pred surprise              1.91             1.61   1.66         1.69   \n",
       "2  normalized pred              1.67             1.41   1.45         1.48   \n",
       "\n",
       "  Researcher  \n",
       "0         25  \n",
       "1       3.91  \n",
       "2       3.42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.39999999999999997\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>62.5 to 65.0</th>\n",
       "      <th>55.0 to 60.0</th>\n",
       "      <th>60.0 to 62.5</th>\n",
       "      <th>65.25 to 67.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   62.5 to 65.0 55.0 to 60.0 60.0 to 62.5 65.25 to 67.0\n",
       "0      gt surprise           16           19           21            22\n",
       "1    pred surprise         0.86         1.00         1.01          0.87\n",
       "2  normalized pred         0.98         1.14         1.15          1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.39999999999999997\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Romantic Comedy</th>\n",
       "      <th>Fantasy Film</th>\n",
       "      <th>Film Based on a Novel</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Musical Film</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Romantic Comedy Fantasy Film Film Based on a Novel Drama  \\\n",
       "0      gt surprise               8           10                    15    23   \n",
       "1    pred surprise            1.02         1.09                  1.08  1.11   \n",
       "2  normalized pred            0.93         1.00                  0.98  1.01   \n",
       "\n",
       "  Musical Film  \n",
       "0           23  \n",
       "1         1.06  \n",
       "2         0.97  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.46169025843831935\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>8.4 to 27.9</th>\n",
       "      <th>2.6 to 5.7</th>\n",
       "      <th>1.5 to 2.5</th>\n",
       "      <th>0.3 to 1.4</th>\n",
       "      <th>0.0 to 0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   8.4 to 27.9 2.6 to 5.7 1.5 to 2.5 0.3 to 1.4 0.0 to 0.2\n",
       "0      gt surprise          15         15         24         25         25\n",
       "1    pred surprise        1.37       1.09       1.13       1.16       1.62\n",
       "2  normalized pred        1.10       0.88       0.91       0.94       1.31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.47434164902525683\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Voice Actor</th>\n",
       "      <th>Musician</th>\n",
       "      <th>Politician</th>\n",
       "      <th>Writer</th>\n",
       "      <th>Chess Player</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.54</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.38</td>\n",
       "      <td>4.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Voice Actor Musician Politician Writer Chess Player\n",
       "0      gt surprise           4       16         22     23           25\n",
       "1    pred surprise        1.19     1.81       1.64   1.54         5.48\n",
       "2  normalized pred        1.07     1.62       1.47   1.38         4.90"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>438,000,000 to 1,590,000,000</th>\n",
       "      <th>1,610,000,000 to 6,745,000,000</th>\n",
       "      <th>113,000,000 to 427,800,000</th>\n",
       "      <th>6,764,000,000 to 217,267,000,000</th>\n",
       "      <th>1 to 108,589,000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   438,000,000 to 1,590,000,000  \\\n",
       "0      gt surprise                           15   \n",
       "1    pred surprise                         0.90   \n",
       "2  normalized pred                         0.75   \n",
       "\n",
       "  1,610,000,000 to 6,745,000,000 113,000,000 to 427,800,000  \\\n",
       "0                             20                         21   \n",
       "1                           0.87                       0.85   \n",
       "2                           0.72                       0.70   \n",
       "\n",
       "  6,764,000,000 to 217,267,000,000 1 to 108,589,000  \n",
       "0                               22               26  \n",
       "1                             0.95             0.98  \n",
       "2                             0.79             0.81  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Singer</th>\n",
       "      <th>Politician</th>\n",
       "      <th>Film Director</th>\n",
       "      <th>Architect</th>\n",
       "      <th>Sport Cyclist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Singer Politician Film Director Architect Sport Cyclist\n",
       "0      gt surprise      0         13            18        26            26\n",
       "1    pred surprise   1.83       1.88          1.82      2.00          3.38\n",
       "2  normalized pred   1.41       1.45          1.40      1.54          2.60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.6668859288553503\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>76.6 to 85.4</th>\n",
       "      <th>73.9 to 76.6</th>\n",
       "      <th>70.2 to 73.8</th>\n",
       "      <th>63.3 to 69.9</th>\n",
       "      <th>51.8 to 63.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   76.6 to 85.4 73.9 to 76.6 70.2 to 73.8 63.3 to 69.9  \\\n",
       "0      gt surprise           18           18           19           23   \n",
       "1    pred surprise         1.11         1.12         1.11         1.28   \n",
       "2  normalized pred         1.12         1.12         1.11         1.28   \n",
       "\n",
       "  51.8 to 63.2  \n",
       "0           26  \n",
       "1         1.44  \n",
       "2         1.44  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.6668859288553503\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Television Presenter</th>\n",
       "      <th>Writer</th>\n",
       "      <th>Television Actor</th>\n",
       "      <th>Film Actor</th>\n",
       "      <th>Film Producer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Television Presenter Writer Television Actor Film Actor  \\\n",
       "0      gt surprise                    4      9               14         16   \n",
       "1    pred surprise                 1.17   1.64             1.23       1.37   \n",
       "2  normalized pred                 0.96   1.35             1.00       1.13   \n",
       "\n",
       "  Film Producer  \n",
       "0            19  \n",
       "1          1.78  \n",
       "2          1.46  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>History Painting</th>\n",
       "      <th>Cityscape</th>\n",
       "      <th>Landscape Art</th>\n",
       "      <th>Portrait</th>\n",
       "      <th>Self-Portrait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   History Painting Cityscape Landscape Art Portrait  \\\n",
       "0      gt surprise                6        19            21       23   \n",
       "1    pred surprise             0.82      0.78          0.80     0.86   \n",
       "2  normalized pred             1.08      1.04          1.06     1.14   \n",
       "\n",
       "  Self-Portrait  \n",
       "0            26  \n",
       "1          1.39  \n",
       "2          1.84  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Russian</th>\n",
       "      <th>English</th>\n",
       "      <th>German</th>\n",
       "      <th>Swedish</th>\n",
       "      <th>Spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Russian English German Swedish Spanish\n",
       "0      gt surprise       1      13     19      20      26\n",
       "1    pred surprise    1.14    1.12   1.16    1.43    1.32\n",
       "2  normalized pred    0.98    0.96   1.00    1.23    1.14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.7999999999999999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Politician</th>\n",
       "      <th>Military Officer</th>\n",
       "      <th>Painter</th>\n",
       "      <th>Rugby Union Player</th>\n",
       "      <th>Singer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Politician Military Officer Painter Rugby Union Player  \\\n",
       "0      gt surprise          1               12      16                 24   \n",
       "1    pred surprise       1.61             1.45    2.25               2.66   \n",
       "2  normalized pred       1.26             1.14    1.76               2.09   \n",
       "\n",
       "  Singer  \n",
       "0     26  \n",
       "1   2.34  \n",
       "2   1.84  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.7999999999999999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Landscape</th>\n",
       "      <th>Sky</th>\n",
       "      <th>Mountain</th>\n",
       "      <th>Virgin Mary</th>\n",
       "      <th>Bridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Landscape   Sky Mountain Virgin Mary Bridge\n",
       "0      gt surprise        10    11       15          18     21\n",
       "1    pred surprise      1.15  1.09     1.22        1.29   1.23\n",
       "2  normalized pred      1.01  0.95     1.06        1.13   1.07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.7999999999999999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Oil Paint</th>\n",
       "      <th>Canvas</th>\n",
       "      <th>Cardboard</th>\n",
       "      <th>Paper</th>\n",
       "      <th>Tempera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Oil Paint Canvas Cardboard Paper Tempera\n",
       "0      gt surprise         0      5        24    24      25\n",
       "1    pred surprise      1.60   1.63      1.70  1.85    1.72\n",
       "2  normalized pred      1.00   1.02      1.06  1.15    1.07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.8207826816681234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>London</th>\n",
       "      <th>New York City</th>\n",
       "      <th>Hamburg</th>\n",
       "      <th>Paris</th>\n",
       "      <th>Rome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   London New York City Hamburg Paris  Rome\n",
       "0      gt surprise      8            20      24    26    26\n",
       "1    pred surprise   1.20          1.35    1.34  1.37  1.54\n",
       "2  normalized pred   0.95          1.07    1.06  1.09  1.22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.8720815992723809\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Singer-songwriter</th>\n",
       "      <th>Film Producer</th>\n",
       "      <th>Entrepreneur</th>\n",
       "      <th>Author</th>\n",
       "      <th>Painter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Singer-songwriter Film Producer Entrepreneur Author Painter\n",
       "0      gt surprise                 1            12           14     19      26\n",
       "1    pred surprise              1.54          1.59         1.55   1.94    2.14\n",
       "2  normalized pred              1.23          1.27         1.24   1.55    1.71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.8999999999999998\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>German</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Swedish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   English French German Russian Swedish\n",
       "0      gt surprise       2     12     15      24      25\n",
       "1    pred surprise    1.11   1.29   1.23    1.44    1.47\n",
       "2  normalized pred    0.96   1.12   1.07    1.25    1.27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.8999999999999998\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>South Africa</th>\n",
       "      <th>United States of America</th>\n",
       "      <th>France</th>\n",
       "      <th>South Korea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Switzerland South Africa United States of America France  \\\n",
       "0      gt surprise           9           18                       20     20   \n",
       "1    pred surprise        1.07         1.10                     1.16   1.19   \n",
       "2  normalized pred        1.03         1.06                     1.11   1.15   \n",
       "\n",
       "  South Korea  \n",
       "0          26  \n",
       "1        1.31  \n",
       "2        1.26  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 0.9746794344808963\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2 or fewer</th>\n",
       "      <th>5 or more</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt surprise</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred surprise</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalized pred</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       4     3 2 or fewer 5 or more\n",
       "0      gt surprise    16    19         20        23\n",
       "1    pred surprise  0.97  0.99       0.99      0.99\n",
       "2  normalized pred  0.82  0.84       0.84      0.84"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman r: 1.0\n"
     ]
    }
   ],
   "source": [
    "for q in sorted(questions, key=lambda q: q[\"spearman\"][emb_name][surprise_metric]):\n",
    "    answers = list(q[\"pred_counts\"].keys())\n",
    "    ans_surprise_gts = [max_count - count for count in q[\"pred_counts\"].values()]\n",
    "    ans_surprise_preds = [q[\"ans_to_surprise_metrics_dict\"][ans][emb_name][surprise_metric] for ans in answers]\n",
    "    surprise_of_ent_in_class = q[\"class_surprise_metrics_dict\"][emb_name][surprise_metric]\n",
    "    ans_surprise_preds_norm = [s / surprise_of_ent_in_class for s in ans_surprise_preds]\n",
    "    gt_order = np.argsort(ans_surprise_gts)\n",
    "    rows = [\n",
    "        [\"\"] + [answers[i] for i in gt_order],\n",
    "        [\"gt surprise\"] + [str(ans_surprise_gts[i]) for i in gt_order],\n",
    "        [\"pred surprise\"] + [f\"{ans_surprise_preds[i]:.2f}\" for i in gt_order],\n",
    "        [\"normalized pred\"] + [f\"{ans_surprise_preds_norm[i]:.2f}\" for i in gt_order]\n",
    "    ]\n",
    "    display(pd.DataFrame(rows[1:], columns=rows[0]))\n",
    "    print(f\"spearman r: {q['spearman'][emb_name][surprise_metric]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41a10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9717f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "850e2405",
   "metadata": {},
   "source": [
    "#### Correlation of true facts (according to WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6935115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c43aba7",
   "metadata": {},
   "source": [
    "#### Correlation of true facts (according to Google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c14c94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644763d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
